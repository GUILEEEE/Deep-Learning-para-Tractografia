{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "024e761d-3f6d-4f13-b105-2810a57cdf95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import torch\n",
    "from dipy.io.streamline import save_tractogram\n",
    "from dipy.tracking.streamline import Streamlines\n",
    "from dipy.io.stateful_tractogram import Space, StatefulTractogram\n",
    "\n",
    "\n",
    "def extract_cubic_neighborhood(x, y, z, data, n=3):\n",
    "    \"\"\"Extrae vecindad 3D manejando bordes\"\"\"\n",
    "    offset = n // 2\n",
    "    if (x - offset < 0) or (x + offset + 1 > data.shape[0]):\n",
    "        return None\n",
    "    if (y - offset < 0) or (y + offset + 1 > data.shape[1]):\n",
    "        return None\n",
    "    if (z - offset < 0) or (z + offset + 1 > data.shape[2]):\n",
    "        return None\n",
    "    return data[x - offset:x + offset + 1, y - offset:y + offset + 1, z - offset:z + offset + 1]\n",
    "\n",
    "\n",
    "class TractographyGenerator:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_path,\n",
    "        peaks_path,\n",
    "        mask_path,\n",
    "        nbh_path,\n",
    "        deep_wm_mask_path=None,\n",
    "        step_size=0.5\n",
    "    ):\n",
    "        # Cargar modelo\n",
    "        self.model = self.load_model(model_path)\n",
    "        self.model.eval()\n",
    "\n",
    "        # Cargar datos de imagen\n",
    "        self.peaks_img = nib.load(peaks_path)\n",
    "        self.peaks_data = self.peaks_img.get_fdata()\n",
    "        self.peaks_affine = self.peaks_img.affine\n",
    "\n",
    "        # Máscara general y máscara de materia blanca profunda\n",
    "        self.mask_data = nib.load(mask_path).get_fdata()\n",
    "        if deep_wm_mask_path:\n",
    "            # Cargar máscara de materia blanca profunda\n",
    "            self.deep_mask_data = nib.load(deep_wm_mask_path).get_fdata().astype(bool)\n",
    "        else:\n",
    "            # Si no se proporciona, usar \n",
    "            # distancia a borde para generar máscara profunda (ejemplo 5 mm)\n",
    "            from scipy.ndimage import distance_transform_edt\n",
    "            binary = self.mask_data > 0\n",
    "            # Suponiendo voxeles isotrópicos, obtener tamaño de voxel en mm\n",
    "            voxel_sizes = np.sqrt((self.peaks_affine[:3, :3] ** 2).sum(axis=0))\n",
    "            dist = distance_transform_edt(binary) * voxel_sizes[0]\n",
    "            self.deep_mask_data = dist > 5.0\n",
    "\n",
    "        self.step = step_size\n",
    "\n",
    "        # Cargar parámetros de normalización\n",
    "        train_data = np.load(nbh_path)\n",
    "        self.X_mean = train_data['inputs'].mean(axis=0)\n",
    "        self.X_std = train_data['inputs'].std(axis=0)\n",
    "\n",
    "    def load_model(self, path):\n",
    "        class MLP(torch.nn.Module):\n",
    "            def __init__(self):\n",
    "                super().__init__()\n",
    "                self.layers = torch.nn.Sequential(\n",
    "                    torch.nn.Linear(408, 512),\n",
    "                    torch.nn.BatchNorm1d(512),\n",
    "                    torch.nn.ReLU(),\n",
    "                    torch.nn.Dropout(0.4),\n",
    "                    torch.nn.Linear(512, 256),\n",
    "                    torch.nn.BatchNorm1d(256),\n",
    "                    torch.nn.ReLU(),\n",
    "                    torch.nn.Dropout(0.3),\n",
    "                    torch.nn.Linear(256, 128),\n",
    "                    torch.nn.BatchNorm1d(128),\n",
    "                    torch.nn.ReLU(),\n",
    "                    torch.nn.Linear(128, 3)\n",
    "                )\n",
    "\n",
    "            def forward(self, x):\n",
    "                return self.layers(x)\n",
    "\n",
    "        model = MLP()\n",
    "        model.load_state_dict(torch.load(path))\n",
    "        return model\n",
    "\n",
    "    def generate_seeds(self, num_seeds):\n",
    "        \"\"\"Genera puntos semilla aleatorios en materia blanca profunda\"\"\"\n",
    "        indices = np.argwhere(self.deep_mask_data)\n",
    "        selected = np.random.choice(len(indices), size=num_seeds, replace=False)\n",
    "        return [nib.affines.apply_affine(self.peaks_affine, idx) for idx in indices[selected]]\n",
    "\n",
    "    def is_in_mask(self, point):\n",
    "        \"\"\"Verifica si un punto está dentro de la máscara\"\"\"\n",
    "        voxel = nib.affines.apply_affine(np.linalg.inv(self.peaks_affine), point)\n",
    "        x,y,z = np.round(voxel).astype(int)\n",
    "        if 0 <= x < self.mask_data.shape[0] and \\\n",
    "           0 <= y < self.mask_data.shape[1] and \\\n",
    "           0 <= z < self.mask_data.shape[2]:\n",
    "            return self.mask_data[x,y,z] > 0\n",
    "        return False\n",
    "    \n",
    "    def predict_direction(self, current_point, prev_dir):\n",
    "        \"\"\"Predice la siguiente dirección usando el modelo\"\"\"\n",
    "        voxel = nib.affines.apply_affine(np.linalg.inv(self.peaks_affine), current_point)\n",
    "        x,y,z = np.round(voxel).astype(int)\n",
    "        \n",
    "        # Extraer vecindad\n",
    "        neighborhood = extract_cubic_neighborhood(x,y,z, self.peaks_data)\n",
    "        if neighborhood is None:\n",
    "            return None\n",
    "        \n",
    "        # Crear input del modelo\n",
    "        input_sample = np.concatenate([\n",
    "            neighborhood.flatten(),\n",
    "            prev_dir.flatten()\n",
    "        ])\n",
    "        \n",
    "        # Normalizar\n",
    "        input_norm = (input_sample - self.X_mean) / (self.X_std + 1e-8)\n",
    "        \n",
    "        # Predecir\n",
    "        with torch.no_grad():\n",
    "            tensor_input = torch.FloatTensor(input_norm).unsqueeze(0)\n",
    "            direction = self.model(tensor_input).numpy().squeeze()\n",
    "        \n",
    "        return direction / np.linalg.norm(direction)\n",
    "\n",
    "    def track(self, seed, max_steps=1000):\n",
    "        streamline = [seed]\n",
    "        current_point = np.array(seed, dtype=np.float32)\n",
    "        \n",
    "        voxel = nib.affines.apply_affine(np.linalg.inv(self.peaks_affine), seed)\n",
    "        x,y,z = np.round(voxel).astype(int)\n",
    "        peaks = self.peaks_data[x,y,z].reshape(5,3)\n",
    "        prev_dir = peaks[0] / np.linalg.norm(peaks[0])+110\n",
    "        \n",
    "        # Configuración de umbral angular (60 grados en radianes)\n",
    "        max_angle_radians = 1.0472  # 60° = 1.0472 rad\n",
    "    \n",
    "        for _ in range(max_steps):\n",
    "            new_dir = self.predict_direction(current_point, prev_dir)\n",
    "            if new_dir is None:\n",
    "                break\n",
    "            \n",
    "            # Calcular ángulo entre dirección anterior y nueva\n",
    "            cos_angle = np.dot(prev_dir, new_dir)\n",
    "            if cos_angle > 1.0: cos_angle = 1.0\n",
    "            if cos_angle < -1.0: cos_angle = -1.0\n",
    "            angle = np.arccos(cos_angle)\n",
    "            \n",
    "            # Detener si el ángulo excede el umbral\n",
    "            if angle > max_angle_radians:\n",
    "                break\n",
    "                \n",
    "            # Actualizar posición\n",
    "            new_point = current_point + self.step * new_dir\n",
    "            \n",
    "            if not self.is_in_mask(new_point):\n",
    "                break\n",
    "            if self.check_self_intersection(streamline, new_point):\n",
    "                break\n",
    "                \n",
    "            streamline.append(new_point.copy())\n",
    "            current_point = new_point\n",
    "            prev_dir = new_dir  # Usar new_dir directamente (ya normalizado)\n",
    "        \n",
    "        return np.array(streamline)\n",
    "    \n",
    "    def check_self_intersection(self, streamline, point, threshold=0.1):\n",
    "        \"\"\"Detecta auto-intersecciones en el streamline\"\"\"\n",
    "        if len(streamline) < 10:\n",
    "            return False\n",
    "        distances = np.linalg.norm(np.array(streamline[-10:]) - point, axis=1)\n",
    "        return np.any(distances < threshold)\n",
    "    \n",
    "    def generate_tractogram(self, num_streamlines, output_path):\n",
    "        \"\"\"Genera múltiples streamlines y guarda el tractograma\"\"\"\n",
    "        seeds = self.generate_seeds(num_streamlines)\n",
    "        streamlines = []\n",
    "        \n",
    "        for seed in seeds:\n",
    "            s = self.track(seed)\n",
    "            if len(s) > 4:  # Descarta streamlines muy cortos\n",
    "                streamlines.append(s)\n",
    "        \n",
    "        # Guardar en formato .tck\n",
    "        sft = StatefulTractogram(streamlines, self.peaks_img, Space.RASMM)\n",
    "        save_tractogram(sft, output_path, bbox_valid_check=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1040a13-abf0-4d54-b7da-c0774222ed83",
   "metadata": {},
   "source": [
    "## Prueba con datos de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1dccdfcf-c07c-41dd-88e9-006b761ac2d1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot take a larger sample than population when 'replace=False'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 12\u001b[0m\n\u001b[1;32m      2\u001b[0m generator \u001b[38;5;241m=\u001b[39m TractographyGenerator(\n\u001b[1;32m      3\u001b[0m     model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/riemann007/JupyterLab/Tesis/MLP/Train_1/best_model.pth\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      4\u001b[0m     peaks_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/riemann007/JupyterLab/Tesis/Proyecto/Datos/Entrenamiento/ISMRM Challenge 2022/ismrm2015_withReversed__peaks.nii.gz\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m     step_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m\n\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m     10\u001b[0m num_sl \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m500000\u001b[39m\n\u001b[0;32m---> 12\u001b[0m \u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_tractogram\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_streamlines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_sl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain_MLP1_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mnum_sl\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.tck\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m     15\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 180\u001b[0m, in \u001b[0;36mTractographyGenerator.generate_tractogram\u001b[0;34m(self, num_streamlines, output_path)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_tractogram\u001b[39m(\u001b[38;5;28mself\u001b[39m, num_streamlines, output_path):\n\u001b[1;32m    179\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Genera múltiples streamlines y guarda el tractograma\"\"\"\u001b[39;00m\n\u001b[0;32m--> 180\u001b[0m     seeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_seeds\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_streamlines\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    181\u001b[0m     streamlines \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m seed \u001b[38;5;129;01min\u001b[39;00m seeds:\n",
      "Cell \u001b[0;32mIn[4], line 91\u001b[0m, in \u001b[0;36mTractographyGenerator.generate_seeds\u001b[0;34m(self, num_seeds)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Genera puntos semilla aleatorios en materia blanca profunda\"\"\"\u001b[39;00m\n\u001b[1;32m     90\u001b[0m indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margwhere(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeep_mask_data)\n\u001b[0;32m---> 91\u001b[0m selected \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoice\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_seeds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [nib\u001b[38;5;241m.\u001b[39maffines\u001b[38;5;241m.\u001b[39mapply_affine(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpeaks_affine, idx) \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices[selected]]\n",
      "File \u001b[0;32mnumpy/random/mtrand.pyx:1001\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot take a larger sample than population when 'replace=False'"
     ]
    }
   ],
   "source": [
    "# Uso del código\n",
    "generator = TractographyGenerator(\n",
    "    model_path = '/home/riemann007/JupyterLab/Tesis/MLP/Train_1/best_model.pth',\n",
    "    peaks_path = '/home/riemann007/JupyterLab/Tesis/Proyecto/Datos/Entrenamiento/ISMRM Challenge 2022/ismrm2015_withReversed__peaks.nii.gz',\n",
    "    mask_path = '/home/riemann007/JupyterLab/Tesis/Proyecto/Datos/Entrenamiento/ISMRM Challenge 2022/ismrm2015_withReversed__local_seeding_mask.nii.gz',\n",
    "    nbh_path = '/home/riemann007/JupyterLab/Tesis/Proyecto/Datos/Entrenamiento/Vecindades/data_100000_n3_k1.npz',\n",
    "    step_size = 0.5\n",
    ")\n",
    "\n",
    "num_sl = 500000\n",
    "\n",
    "generator.generate_tractogram(\n",
    "    num_streamlines=num_sl,\n",
    "    output_path=f'train_MLP1_{num_sl}.tck'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852dfdbf-b246-459b-bd63-7e754835656d",
   "metadata": {},
   "source": [
    "## Prueba con datos de validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33d37634-9594-4062-9cc2-64e72e42abe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uso del código\n",
    "generator = TractographyGenerator(\n",
    "    model_path = '/home/riemann007/JupyterLab/Tesis/MLP/Train_1/best_model.pth',\n",
    "    peaks_path = '/home/riemann007/JupyterLab/Tesis/MLP/Train_1/generated_peaks_csd.nii.gz',\n",
    "    mask_path = '/home/riemann007/JupyterLab/Tesis/masks_validation/wm_mask_fa0.22.nii.gz',\n",
    "    nbh_path = '/home/riemann007/JupyterLab/Tesis/Proyecto/Datos/Entrenamiento/Vecindades/data_100000_n3_k1.npz',\n",
    "    step_size = 0.5\n",
    ")\n",
    "\n",
    "num_sl = 100\n",
    "\n",
    "generator.generate_tractogram(\n",
    "    num_streamlines=num_sl,\n",
    "    output_path=f'validacion0.1_MLP1_{num_sl}.tck'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db9d2222-89c8-4c99-8091-8f9ef32d4eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de ejecución en hrs:  6.319953709178501\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "num_sl = 40000\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "generator.generate_tractogram(\n",
    "    num_streamlines=num_sl,\n",
    "    output_path=f'validacion0.1_MLP1_{num_sl}.tck'\n",
    ")\n",
    "\n",
    "t2 = time.time()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "16b5ad99-44c8-45a2-ad0c-9aabdca50e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de ejecución en hrs:  0.6319953709178501\n"
     ]
    }
   ],
   "source": [
    "print(\"Tiempo de ejecución en hrs: \", (t2-t1)/3600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bb4a25-c0e9-415a-a743-bc32b2911076",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
